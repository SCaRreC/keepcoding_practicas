---
format: html
editor: visual
  markdown: 
    wrap: 72
---

Vasmos a cargar el dataset de AirBnB descargado de [aquí](https://public.opendatasoft.com/explore/dataset/airbnb-listings/export/?disjunctive.host_verifications&disjunctive.amenities&disjunctive.features&q=Madrid&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQ09VTlQiLCJ5QXhpcyI6Imhvc3RfbGlzdGluZ3NfY291bnQiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiJyYW5nZS1jdXN0b20ifV0sInhBeGlzIjoiY2l0eSIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6IiIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJyb29tX3R5cGUiLCJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1saXN0aW5ncyIsIm9wdGlvbnMiOnsiZGlzanVuY3RpdmUuaG9zdF92ZXJpZmljYXRpb25zIjp0cnVlLCJkaXNqdW5jdGl2ZS5hbWVuaXRpZXMiOnRydWUsImRpc2p1bmN0aXZlLmZlYXR1cmVzIjp0cnVlfX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=16,41.38377,2.15774&basemap=jawg.streets)

![](descargar.png)

```{r}
airbnb<-read.csv('/Users/saracarcamo/Documents/KeepCoding/Estadistica_DataMining/estadistica-datamining-main/data/airbnb-listings.csv',sep = ';')
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)
head(airbnb)
```

1.  Vamos a quedarnos con las columnas de mayor interés: 'City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude' Nos quedarmos solo con las entradas de Madrid para Room.Type=="Entire home/apt" y cuyo barrio (Neighbourhood) no está vacio '' Podemos eliminar las siguientes columnas que ya no son necesarias: "Room.Type",'City' Llama a nuevo dataframe df_madrid.

```{r}
df_airbnb <- data.frame(airbnb[,c('City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')])
df_madrid <- df_airbnb[df_airbnb$City == 'Madrid' & df_airbnb$Room.Type == "Entire home/apt" & df_airbnb$Neighbourhood != "", ]

head(df_madrid)
#summary(df_madrid)
dim(df_madrid)
```

------------------------------------------------------------------------

2.  Crea una nueva columna llamada Square.Meters a partir de Square.Feet. Recuerda que un pie cuadrado son 0.092903 metros cuadrados.

```{r}
df_madrid$Square.Meters <- df_madrid$Square.Feet * 0.092903
head(df_madrid)
```

------------------------------------------------------------------------

3.  ¿Que porcentaje de los apartamentos no muestran los metros cuadrados? Es decir, ¿cuantos tienen NA en Square.Meters?

```{r}
NA_percentage <- (sum(is.na(df_madrid$Square.Meters))/length(df_madrid$Square.Meters))*100
print(paste("El porcentage de NA en la columna de Square.Meters es: ", sprintf("%.2f", NA_percentage), "%"))
```

------------------------------------------------------------------------

4.  De todos los apartamentos que tienen un valor de metros cuadrados diferente de NA ¿Que porcentaje de los apartamentos tienen 0 metros cuadrados?

```{r}
sqm0_percentage <- length(df_madrid$Square.Meters[which(df_madrid$Square.Meters == 0)])/length(df_madrid$Square.Meters[!is.na(df_madrid$Square.Meters)]) * 100
print(paste("El porcentage de apartamentos con 0 metros cuadrados es: ", sprintf("%.2f", sqm0_percentage), "%"))
```

------------------------------------------------------------------------

5.  Reemplazar todos los 0m\^2 por NA

```{r}
df_madrid$Square.Meters[which(df_madrid$Square.Meters == 0)] <- NA

```

------------------------------------------------------------------------

Hay muchos NAs, vamos a intentar crear un modelo que nos prediga cuantos son los metros cuadrados en función del resto de variables para tratar de rellenar esos NA. Pero **antes de crear el modelo** vamos a hacer: \* pintar el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más. \* crear una variable sintética nueva basada en la similitud entre barrios que usaremos en nuestro modelo.

6.  Pinta el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más

```{r}
library(dplyr)
library(ggplot2)

ggplot(data = df_madrid, aes(x=Square.Meters)) +
geom_histogram(fill='#7070BB', color='#2020EE', breaks=seq(0,500, by=20)) +
geom_boxplot(color='red', width=6, alpha=0.5)+
xlab('metros cuadrados')+ylab('numero de propiedades')
```

------------------------------------------------------------------------

```{r}
# A simple vista, eliminaria los outliers de los valores más altos. 
library(dplyr)

df_madrid <- df_madrid |> filter(Square.Meters < 400)

ggplot(data = df_madrid, aes(x=Square.Meters)) +
    geom_histogram(fill='#7070BB', color='#2020EE', breaks=seq(0,500, by=20)) +
    geom_boxplot(color='red', width=6, alpha=0.5)+
    xlab('metros cuadrados')+ylab('numero de propiedades')

```

7.  Asigna el valor NA a la columna Square.Meters de los apartamentos que tengan menos de 20 m\^2

```{r}
df_madrid$Square.Meters[which(df_madrid$Square.Meters <= 20)] <- NA
```

------------------------------------------------------------------------

8.  Existen varios Barrios que todas sus entradas de Square.Meters son NA, vamos a eliminar del dataset todos los pisos que pertenecen a estos barrios.

```{r}
library(dplyr)

df_madrid_grouped <- df_madrid |> group_by(Neighbourhood) |> summarize(num_pisos=n(), num_na = sum(is.na(Square.Meters)))
# Selecciono aquellos vecindarios que tienen numero de pisos = numero de NA. Porque esos son los que todas sus entradas son NAs
df_madrid_wona <- df_madrid_grouped|> filter(num_pisos == num_na)
# Me quedo con un vector de los nombres de esos vecindarios 
na_neighbourhoods <- c(df_madrid_wona$Neighbourhood)
# Elimino del df original esos vecindarios.
df_madrid <- df_madrid |> filter(!Neighbourhood %in% na_neighbourhoods)


```

```         
------------------------------------------------------------------------
```

9.  ¿Tienen todos los barrios los mismos metros cuadrados de media? ¿Con que test lo comprobarías?

```{r}
# Primero compruebo que la distribucion de los metros cuadrados siga una distribucion normal o no con Q-Q_plot.
paste("Los metros cuadrados de cada barrio NO siguen una distribucion Gaussiana después de hacer los ajustes. pvalor:",
          shapiro.test(df_madrid$Square.Meters)$p.value)
qqnorm(df_madrid$Square.Meters)
qqline(df_madrid$Square.Meters, col="red")


```

```         
------------------------------------------------------------------------
```

```{r}
# Como no sigue una distribución normal, analizamos si existen diferencias entre las medias de cada barrio con el test de Kruskal-Wallis

Neighbour <- df_madrid$Neighbourhood # asigno la columna de Neighbouhood a una variable para simplificar futuras referencias a ella en el código
Sq_meters <- df_madrid$Square.Meters # hago lo mismo con la columna de metros cuadrados.

test_Kruskal <- kruskal.test(Sq_meters ~ Neighbour, data=df_madrid)
print(test_Kruskal)
paste("Se rechaza la Hipotesis nula. p-value:", round(test_Kruskal$p.value, 4), "Lo que significa que al menos uno de los barrios tiene una mediana diferente de los demás.")
```

10. Vamos a agrupar los barrios por metros cuadrados. Podemos usar una matriz de similaridad de Tukey. Muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos. ¿Como se diferencia la media del Barrio A al Barrio B? (Es decir, cual sería el pvalor suponiendo una H0 en la que las medias son iguales)

```{r}
test_tukey <- TukeyHSD(aov( Sq_meters ~ Neighbour, data=df_madrid))

test_tukey.result<-data.frame(test_tukey$Neighbour) # Guardo la columna del resultado de Test de Tukey que contiene las comparaciones dos a dos de los barrios en un data frame.
cn <-sort(unique(df_madrid$Neighbourhood)) # Extraer y ordenar los niveles de 'Neighbour'. 
resm <- matrix(NA, length(cn),length(cn)) # Creo matriz vacía de dimensiones length(cn)
rownames(resm) <- cn # nombro filas y columnas
colnames(resm) <- cn
resm[lower.tri(resm) ] <- round(test_tukey.result$p.adj,4) # relleno la diagonal inferior con los p-values del Test de Tukey.
resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] # relleno la diagonal superior.
diag(resm) <- 1 # Añado 1s en la diagonal


```

------------------------------------------------------------------------

```{r}
# Representación gráfica del Test de Tukey entre los barrios

library(ggplot2)
library(reshape2)
dfResm <- melt(resm)
ggplot(dfResm, aes(x=Var1, y=Var2, fill=value))+
  geom_tile(colour = "black")+
  geom_text(aes(label=round(value, 2)),size = 1) +
  scale_fill_gradient(low = "white",high = "steelblue")+
  ylab("Neighbourhood")+xlab("Neighbourhood")+theme_bw()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position="none")
```

```{r}
# P-valores cercanos a 1, significan similitud entre las medias, y los valures cercanos a 0, significa que esos barrios tienen distintas medias. 
# En este caso, los barrios de Rios Rosas, Fuente del Berro y El Tréntaiseis son diferentes a los demás.
```

11. En el punto anterior has creado una matriz de p-valores que indica como de parecidos son dos barrios. Si su pvalor es bajo significa que los barrios son diferentes, si es alto significa que los barrios se parecen. Esta matriz la podemos usar como matriz de distancia si restamos el pvalor a 1. Es decir si usamos como distancia 1-pvalor. De esta forma barrios con un pvalor alto tendrán una distancia mayor que aquellos con un pvalor bajo. Usando esta última métrica como matriz de distancias dibuja un dendrograma de los diferentes barrios.

```{r}
d <- as.dist(1-resm) # Utilizo 1-(p-value) como dato de distancia para hacer los clusters.
dist.tree <- hclust(d, method="complete")
dist.dend <- as.dendrogram(dist.tree) 
par(cex = 0.5)
plot(dist.dend)
# El punto de corte podría en 0.4 para dejar 3 clusters.
```

------------------------------------------------------------------------

10. ¿Que punto de corte sería el aconsejable?, ¿cuantos clusters aparecen?

```{r}
# Hay tres clusters bien definidos, asi que pondría el punto de corte en 0.4 y luego analizo los clusters resultantes con silhouette.

library(dendextend)
dend <- dist.dend |> set("labels_cex", 0.6)
clusters <- cutree(dist.dend, h=0.4)
plot(color_branches(dend, h=0.4))


```

```{r}
library(cluster)
k <- length(unique(clusters))
ss <- silhouette(clusters, d)
summary(ss)
plot(ss, col=1:k, border=NA)

# Vemos que los clusters creados, aunque aparentes en el dendrograma, son un poco cuestionables según el valor de Silhouette, puede que debido al reducido número de muestras completas.
```

```         
------------------------------------------------------------------------
```

11. Vamos a crear una nueva columna en el dataframe df_madrid con un nuevo identificador marcado por los clusters obtenidos. Esta columna la llamaremos neighb_id

```{r}
   
library(dplyr)

   df_madrid <- df_madrid |> group_by(Neighbourhood) |> mutate(neighb_id = factor(clusters[match(Neighbourhood, names(clusters))]))
   df_madrid <- df_madrid |> ungroup(Neighbourhood)
   
   head(df_madrid)
```

------------------------------------------------------------------------

12. Vamos a crear dos grupos, uno test y otro train.

```{r}
set.seed(124)

train_size <- round(0.7 * nrow(df_madrid)) # Cojo el 70% de los datos aleatorios para trainig y el 30% para testing

train_ind <- sample(1:nrow(df_madrid), size = train_size)

madrid.train <- df_madrid[train_ind,]
madrid.test <- df_madrid[-train_ind,]
  
summary(madrid.train)
summary(madrid.test)
```

------------------------------------------------------------------------

13. Tratamos de predecir los metros cuadrados en función del resto de columnas del dataframe.

```{r}
# Aplicando regresión lineal sobre las variables que considero importantes, sin estandarizar y sin seleccionarlas basadas en ninguna método analítico (al calcular correlaciones entre variables y seleccionar aquellas que tenían correlacciones más altas, el modelo me daba peores valores de R-sq y RMSD.

madrid.train <- na.omit(madrid.train) # Tengo que añadir esta linea porque más adelante me daba error para filtrar outliers con la distancia de Cooks.

model <- lm(data=madrid.train, formula = Square.Meters~Accommodates+Bathrooms+Bedrooms+Beds+Price+Guests.Included+Extra.People+Review.Scores.Rating+neighb_id)

summary(model) 
```

------------------------------------------------------------------------

14. Evaluar la calidad de vuestro modelo

```{r}
# Análisis de la R-squared y RMSE

library(caret)

madrid.test$sqm_est <- predict(model, madrid.test)
madrid.train$sqm_est <- predict(model, madrid.train)
df_sqm <- data.frame(merge(madrid.test$Square.Meters,madrid.test$sqm_est ))
df_sqm <- data.frame(merge(madrid.train$Square.Meters,madrid.train$sqm_est ))

print("Training:")
postResample(madrid.train$sqm_est,obs = madrid.train$Square.Meters)
print("Testing:")
postResample(madrid.test$sqm_est,obs = madrid.test$Square.Meters)

```

```{r}

# Representacion de los residuos
hist(model$residual)

# Residuos distribuidos más o menos normalmente, pero con algunos outliers. 
# Pensé en calcular la distancia de Cooks para limpiar los outliers del data set de training y mejorar el modelo, pero debido a que tenemos muy pocos datos y que he visto que los resultados de R-square y RMSE fluctuan en cada ejecución del modelo, prefiero dejar los pocos datos que tengo para tener mas representaciones. 
```

------------------------------------------------------------------------

15. Si tuvieramos un anuncio de un apartamento para 6 personas (Accommodates), con 1 baño, con un precio de 80€/noche y 3 habitaciones en el barrio de Sol, con 3 camas y un review de 80. ¿Cuantos metros cuadrados tendría? Si tu modelo necesita algúna variable adicional puedes inventartela dentro del rango de valores del dataset. ¿Como varía sus metros cuadrados con cada habitación adicional?

```{r}
x <- data.frame("Neighbourhood" = "Sol", "Accommodates" = 6, "Bathrooms" = 1, "Price" = 80, "Bedrooms" = 3, "Beds" = 3, "Review.Scores.Rating" = 80, "Guests.Included" = 0, "Extra.People" = 2, "neighb_id" = "2")
predicction <- predict(model_madrid_clean, x)
paste("El apartamento del anuncio mencionado, tendría ", round(predicction, 2), "metros cuadrados, según nuestro modelo predictivo")
```

------------------------------------------------------------------------

16. Rellenar los Square.Meters con valor NA con el estimado con el modelo anterior.
```{r}
df_nas <- df_madrid |> filter(is.na(Square.Meters))
paste("Despues de imputar los valores estimados de metros cuadrados, comprobamos que todas las filas tienen un valor estimado de Square.Meters.", "Número de filas con NA =", nrow(df_nas))
```

```{r}
# Nueva distribución de los datos de metros cuadrados.
ggplot(data = df_madrid, aes(x=Square.Meters)) +
geom_histogram(fill='#7070BB', color='#2020EE', breaks=seq(0,500, by=20)) +
xlab('metros cuadrados')+ylab('numero de propiedades')
```

------------------------------------------------------------------------
